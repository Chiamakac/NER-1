{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL Final Copy of Fine-Tune-BERT-for-Text-Classification-with-TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiamaka249/ChiamakaNER/blob/master/FINAL_Final_Copy_of_Fine_Tune_BERT_for_Text_Classification_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGCJYkQj_Uu2"
      },
      "source": [
        "<h2 align=center> Fine-Tune BERT for Text Classification with TensorFlow</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y2m1S6e12il"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 1: BERT Classification Model</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYYYWqWr_WCC"
      },
      "source": [
        "In this [project](https://www.coursera.org/projects/fine-tune-bert-tensorflow/), you will learn how to fine-tune a BERT model for text classification using TensorFlow and TF-Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQG5PCO_WFx"
      },
      "source": [
        "The pretrained BERT model used in this project is [available](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) on [TensorFlow Hub](https://tfhub.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pKNS21u_WJo"
      },
      "source": [
        "### Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3NHSMXv_WMv"
      },
      "source": [
        "By the time you complete this project, you will be able to:\n",
        "\n",
        "- Build TensorFlow Input Pipelines for Text Data with the [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) API\n",
        "- Tokenize and Preprocess Text for BERT\n",
        "- Fine-tune BERT for text classification with TensorFlow 2 and [TF Hub](https://tfhub.dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6BEe-3-AVRQ"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc9f-8rLAVUS"
      },
      "source": [
        "In order to be successful with this project, it is assumed you are:\n",
        "\n",
        "- Competent in the Python programming language\n",
        "- Familiar with deep learning for Natural Language Processing (NLP)\n",
        "- Familiar with TensorFlow, and its Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYXXV5n3Ab-4"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhK-SYGyAjxe"
      },
      "source": [
        "This project/notebook consists of several Tasks.\n",
        "\n",
        "- **[Task 1]()**: Introduction to the Project.\n",
        "- **[Task 2]()**: Setup your TensorFlow and Colab Runtime\n",
        "- **[Task 3]()**: Download and Import the Quora Insincere Questions Dataset\n",
        "- **[Task 4]()**: Create tf.data.Datasets for Training and Evaluation\n",
        "- **[Task 5]()**: Download a Pre-trained BERT Model from TensorFlow Hub\n",
        "- **[Task 6]()**: Tokenize and Preprocess Text for BERT\n",
        "- **[Task 7]()**: Wrap a Python Function into a TensorFlow op for Eager Execution\n",
        "- **[Task 8]()**: Create a TensorFlow Input Pipeline with `tf.data`\n",
        "- **[Task 9]()**: Add a Classification Head to the BERT `hub.KerasLayer`\n",
        "- **[Task 10]()**: Fine-Tune BERT for Text Classification\n",
        "- **[Task 11]()**: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaArqXjRAcBa"
      },
      "source": [
        "## Task 2: Setup your TensorFlow and Colab Runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDhjzZ5A4Q_"
      },
      "source": [
        "You will only be able to use the Colab Notebook after you save it to your Google Drive folder. Click on the File menu and select “Save a copy in Drive…\n",
        "\n",
        "![Copy to Drive](https://drive.google.com/uc?id=1CH3eDmuJL8WR0AP1r3UE6sOPuqq8_Wl7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpe6GhLuBJWB"
      },
      "source": [
        "### Check GPU Availability\n",
        "\n",
        "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
        "\n",
        "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V9c8vzSL3aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401e4111-b566-411a-ad6a-8f8c226fad38"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 18 11:16:27 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obch3rAuBVf0"
      },
      "source": [
        "### Install TensorFlow and TensorFlow Model Garden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU3YLZ1TYKUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68757b3b-c42c-4df5-adde-4715d731dbbd"
      },
      "source": [
        "!pip install -q tensorflow==2.3.0"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 26.1 MB 67 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.30.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQEY3dFB0jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3df963-af8c-44f2-c8ec-826546525f41"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFRTC-zwUy6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08213bd-25c2-4c0b-e102-096583ee1a43"
      },
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2G0571zLLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f573a278-4e29-4a6d-8b55-7a333db94bab"
      },
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "tensorflow 2.3.0 requires scipy==1.4.1, but you have scipy 1.7.2 which is incompatible.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.30.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVjksk4yCXur"
      },
      "source": [
        "## Restart the Runtime\n",
        "\n",
        "**Note** \n",
        "After installing the required Python packages, you'll need to restart the Colab Runtime Engine (Menu > Runtime > Restart runtime...)\n",
        "\n",
        "![Restart of the Colab Runtime Engine](https://drive.google.com/uc?id=1xnjAy2sxIymKhydkqb0RKzgVK9rh3teH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMsEoT3Fg4Wg"
      },
      "source": [
        "## Task 3: Download and Import the Quora Insincere Questions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmqEylyFYTdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15c2588-dee2-4c89-dc31-31b8c7995b46"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuX1lB8pPJ-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9bf479-1607-4d3a-f1da-203eabbd1c07"
      },
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version:  2.3.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is NOT AVAILABLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtbwpWgyEZg7"
      },
      "source": [
        "A downloadable copy of the [Quora Insincere Questions Classification data](https://www.kaggle.com/c/quora-insincere-questions-classification/data) can be found [https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip](https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip). Decompress and read the data into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nI-9itVwCCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a535f2-5ed3-43de-db10-0e91ce757c77"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip',\n",
        "              compression='zip', low_memory=False)\n",
        "df.shape\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHE98KiMvDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "56f434cc-418a-48f8-e05f-e2f268c2e026"
      },
      "source": [
        "df.tail(20)\n",
        "# to view the last 20 lines of the dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1306102</th>\n",
              "      <td>ffff3778790af9baae76</td>\n",
              "      <td>What steps can I take to live a normal life if...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306103</th>\n",
              "      <td>ffff3f0a2449ffe4b9ff</td>\n",
              "      <td>Isn't Trump right after all? Why should the US...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306104</th>\n",
              "      <td>ffff41393389d4206066</td>\n",
              "      <td>Is 33 too late for a career in creative advert...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306105</th>\n",
              "      <td>ffff42493fc203cd9532</td>\n",
              "      <td>What is difference between the filteration wor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306106</th>\n",
              "      <td>ffff48dd47bee89fff79</td>\n",
              "      <td>If the universe \"popped\" into existence from n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306107</th>\n",
              "      <td>ffff5fd051a032f32a39</td>\n",
              "      <td>How does a shared service technology team meas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306108</th>\n",
              "      <td>ffff6d528040d3888b93</td>\n",
              "      <td>How is DSATM civil engineering?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306109</th>\n",
              "      <td>ffff8776cd30cdc8d7f8</td>\n",
              "      <td>Do you know any problem that depends solely on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306110</th>\n",
              "      <td>ffff94d427ade3716cd1</td>\n",
              "      <td>What are some comic ideas for you Tube videos ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306111</th>\n",
              "      <td>ffffa382c58368071dc9</td>\n",
              "      <td>If you had $10 million of Bitcoin, could you s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306112</th>\n",
              "      <td>ffffa5b0fa76431c063f</td>\n",
              "      <td>Are you ashamed of being an Indian?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306113</th>\n",
              "      <td>ffffae5dbda3dc9e9771</td>\n",
              "      <td>What are the methods to determine fossil ages ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306114</th>\n",
              "      <td>ffffba7c4888798571c1</td>\n",
              "      <td>What is your story today?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306115</th>\n",
              "      <td>ffffc0c7158658a06fd9</td>\n",
              "      <td>How do I consume 150 gms protein daily both ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306116</th>\n",
              "      <td>ffffc404da586ac5a08f</td>\n",
              "      <td>What are the good career options for a msc che...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306117</th>\n",
              "      <td>ffffcc4e2331aaf1e41e</td>\n",
              "      <td>What other technical skills do you need as a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306118</th>\n",
              "      <td>ffffd431801e5a2f4861</td>\n",
              "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306119</th>\n",
              "      <td>ffffd48fb36b63db010c</td>\n",
              "      <td>Is foam insulation toxic?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306120</th>\n",
              "      <td>ffffec519fa37cf60c78</td>\n",
              "      <td>How can one start a research project based on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306121</th>\n",
              "      <td>ffffed09fedb5088744a</td>\n",
              "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          qid  ... target\n",
              "1306102  ffff3778790af9baae76  ...      0\n",
              "1306103  ffff3f0a2449ffe4b9ff  ...      1\n",
              "1306104  ffff41393389d4206066  ...      0\n",
              "1306105  ffff42493fc203cd9532  ...      0\n",
              "1306106  ffff48dd47bee89fff79  ...      0\n",
              "1306107  ffff5fd051a032f32a39  ...      0\n",
              "1306108  ffff6d528040d3888b93  ...      0\n",
              "1306109  ffff8776cd30cdc8d7f8  ...      0\n",
              "1306110  ffff94d427ade3716cd1  ...      0\n",
              "1306111  ffffa382c58368071dc9  ...      0\n",
              "1306112  ffffa5b0fa76431c063f  ...      1\n",
              "1306113  ffffae5dbda3dc9e9771  ...      0\n",
              "1306114  ffffba7c4888798571c1  ...      0\n",
              "1306115  ffffc0c7158658a06fd9  ...      0\n",
              "1306116  ffffc404da586ac5a08f  ...      0\n",
              "1306117  ffffcc4e2331aaf1e41e  ...      0\n",
              "1306118  ffffd431801e5a2f4861  ...      0\n",
              "1306119  ffffd48fb36b63db010c  ...      0\n",
              "1306120  ffffec519fa37cf60c78  ...      0\n",
              "1306121  ffffed09fedb5088744a  ...      0\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leRFRWJMocVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ff07d517-8de6-4dfc-ee0e-cb849886cc37"
      },
      "source": [
        "df.target.plot(kind='hist', title ='Target distribution');\n",
        "# Note that the distribution is skewd to sincere sentences (ie. class imbalance problem)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELjswHcFHfp3"
      },
      "source": [
        "## Task 4: Create tf.data.Datasets for Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcbNUMLEgE40"
      },
      "source": [
        "This splits the dataset to training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fScULIGPwuWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eebb633-9233-45da-dcf9-ec644ecad291"
      },
      "source": [
        "train_df, remaining = train_test_split(df,random_state=42, train_size=0.0075, stratify=df.target.values)\n",
        "valid_df, _ = train_test_split(remaining, random_state=42, train_size=0.00075, stratify=remaining.target.values)\n",
        "train_df.shape, valid_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9795, 3), (972, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQYMGT5_qLPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10762f6a-3d42-4a01-de8e-2351ae407c98"
      },
      "source": [
        "# to create a tf dataset for the traininig and validation dataset\n",
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_df['question_text']. values, train_df['target'].values))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((valid_df.question_text.values, valid_df.target.values))\n",
        "\n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Why are unhealthy relationships so desirable?', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2-ReN88Hvy_"
      },
      "source": [
        "## Task 5: Download a Pre-trained BERT Model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMb5M86b4-BU"
      },
      "source": [
        "\"\"\"\n",
        "Each line of the dataset is composed of the review text and its label\n",
        "- Data preprocessing consists of transforming text to BERT input features:\n",
        "input_word_ids, input_mask, segment_ids\n",
        "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
        "\"\"\"\n",
        "\n",
        "label_list = [0, 1] # Label categories\n",
        "max_seq_length = 128 # maximum length of (token) input sequences\n",
        "train_batch_size = 32\n",
        "\n",
        "\n",
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEUezMK-zkkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a2e056-771b-4361-b0d6-ce4880117da0"
      },
      "source": [
        "#tokenization\n",
        "tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing?')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '##,', 'how', 'are', 'you', 'doing', '##?']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AFsmTO5JSmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0719eb5-f0d3-42a8-fb49-ff4c45141645"
      },
      "source": [
        "#Convert tokens to input ids\n",
        "tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing?'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7632, 29623, 2129, 2024, 2017, 2725, 29632]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z44MkRggz16G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f64eb1-7169-4b66-d52b-44e093edadf9"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens([7632, 29623, 2129, 2024, 2017, 2725, 29632])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '##,', 'how', 'are', 'you', 'doing', '##?']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI2KbGvh10V9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QinzNq6OsP1"
      },
      "source": [
        "## Task 6: Tokenize and Preprocess Text for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FTqJ698zZ1e"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1-SpKFELnEvBMBqO7h3iypo8q9uUUo96P' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 2: BERT Tokenizer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYkggYe6HZc"
      },
      "source": [
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create InputExamples using `classifier_data_lib`'s constructor `InputExample` provided in the BERT library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-21A5aNJM0W"
      },
      "source": [
        "# This provides a function to convert row to input features and label\n",
        "\n",
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid=None,\n",
        "                                             text_a = text.numpy(),\n",
        "                                             text_b = None,\n",
        "                                             label = label.numpy())\n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list, max_seq_length, tokenizer)\n",
        "  \n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_HQSsHwWCsK"
      },
      "source": [
        "You want to use [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply this function to each element of the dataset. [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) runs in graph mode.\n",
        "\n",
        "- Graph tensors do not have a value.\n",
        "- In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function). The [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNlkKVfWX0Q"
      },
      "source": [
        "## Task 7: Wrap a Python Function into a TensorFlow op for Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGACBcfCWC2O"
      },
      "source": [
        "def to_feature_map(text, label_):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp=[text, label],\n",
        "                                                                Tout=[tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "      'input_word_ids' : input_ids,\n",
        "       'input_mask' : input_mask,\n",
        "       'input_type_ids' : segment_ids\n",
        "  }\n",
        "  \n",
        "  return (x, label_id)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdO6MjTbtn1"
      },
      "source": [
        "## Task 8: Create a TensorFlow Input Pipeline with `tf.data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHRdiO3dnPNr"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  train_data = (train_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder=True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  \n",
        "  # valid\n",
        "  valid_data = (valid_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .batch(32, drop_remainder=True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLUWnfx-YDi2"
      },
      "source": [
        "The resulting `tf.data.Datasets` return `(features, labels)` pairs, as expected by [`keras.Model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Z2cy9GHQ8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ac15ec-494e-4730-dff1-bc74aa85e8d0"
      },
      "source": [
        "# train data spec\n",
        "train_data.element_spec\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGAH-ycYOmao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d8c49b-e7b5-4e2b-f8b2-1180b293d023"
      },
      "source": [
        "# valid data spec\n",
        "valid_data.enumerate\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DatasetV2.enumerate of <TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxe-7yhPyQe"
      },
      "source": [
        "## Task 9: Add a Classification Head to the BERT Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9THH5V0Dw2HO"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 3: BERT Layer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9il4gtlADcp"
      },
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "  \n",
        "  drop = tf.keras.layers.Dropout(0,4) (pooled_out)\n",
        "  output = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\") (drop)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "      inputs={\n",
        "          'inputs_word_ids': input_ids,\n",
        "          'input_mask' : input_mask,\n",
        "          'input_type_ids': input_type_ids \n",
        "      },\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6maM-vr7YaJ"
      },
      "source": [
        "## Task 10: Fine-Tune BERT for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptCtiiONsBgo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJaFnkbMtPL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcREcgPUHr9O"
      },
      "source": [
        "# Train model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZl1lx_cA5Y"
      },
      "source": [
        "## Task 11: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCjgrUYH_IsE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6lrFRra_KmA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opu9neBA_98R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkhtCCgnUbY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4B8NQBLd9rN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeVNOGfFJT9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_YWudFRJT__"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hENB__IlJUCk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkYpiGrhJUFK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqbQZJnJUHw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKuBGgfJUKv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}